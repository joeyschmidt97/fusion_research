{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c65584b-dc97-4f42-bc54-8e86bc7a6c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24320"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.chdir('/global/u1/j/joeschm')\n",
    "os.system(\"sacct -u joeschm -X --format=jobid,jobname,state,start,end,timelimit,elapsed -S 06/15/21-00:00:00 -p > test.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379f41c2-22f3-4d09-a661-37b9a1d2988f",
   "metadata": {},
   "source": [
    "## Add Job Info to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e69d2bf-23c8-4a54-b817-7afbd1de6685",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('test.txt', 'r')\n",
    "read_content = file.read()\n",
    "chunks = read_content.split('\\n')\n",
    "\n",
    "header = chunks[0].split('|')[:-1]           #header column for dataframe and drop empty '' at the end\n",
    "\n",
    "jobs_df = pd.DataFrame(columns = header)\n",
    "\n",
    "\n",
    "\n",
    "for string in chunks[1:-1]:  #run through list of entries omitting first entry which is the header and final entry which is blank\n",
    "    entry = string.split('|')[:-1]           #drop empty '' at the end\n",
    "    \n",
    "    job_entry = pd.DataFrame([entry], columns = header) #create single job entry\n",
    "    jobs_df = jobs_df.append(job_entry, ignore_index = True)  #append job entry to job dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a4b47b-2ba2-4f9d-94fa-64fbfae1a2ba",
   "metadata": {},
   "source": [
    "## Associate JobID with Output Filepath & Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e683449-4599-4782-8e3f-3b9957aacd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENE_path = '/global/homes/j/joeschm/GENE'\n",
    "os.chdir(GENE_path)\n",
    "\n",
    "col = [\"JobID\",\"Path\",\"Problem\"]\n",
    "output_path_df = pd.jobs = pd.DataFrame(columns = col)\n",
    "\n",
    "for filename in os.listdir(os.getcwd()):\n",
    "    if filename.startswith(\"prob_\"):\n",
    "        prob_path = GENE_path + \"/\" + filename\n",
    "        os.chdir(prob_path) #change into GENE prob directory to search for GENE.XXXX.out files\n",
    "        \n",
    "        #print(\"\")\n",
    "        #print(filename)\n",
    "        \n",
    "        for GENEfile in os.listdir(os.getcwd()):\n",
    "            #scan through all files in GENE prob directory\n",
    "            \n",
    "            path_found = False           #reset filepath data dump for every new GENE.XXXX.out file\n",
    "            \n",
    "            if GENEfile.startswith(\"GENE.\") and GENEfile.endswith(\"out\"):\n",
    "                jobID = GENEfile[5:-4]        #get XXXX jobID in GENE.XXXX.out file\n",
    "\n",
    "                \n",
    "                file = open(GENEfile, 'r')    #open text file\n",
    "                text = file.read()            #read text file\n",
    "                line_list = text.split('\\n')  #split into list using newline\n",
    "\n",
    "                for line in line_list:\n",
    "                    line = line.replace(\" \",\"\")     #remove spaces from within lines\n",
    "                    if 'SCANDIR' in line:           #if a line has \n",
    "                        for i in range(len(line)):  #scan through line character-by-character\n",
    "                            if line[i] == '=':\n",
    "                                data_path = line[i+1:]  #add /filepath \n",
    "                                path_found = True\n",
    "                                break    #once the filepath is found exit the search   \n",
    "                        break            #break out of the list line search if 'SCANDIR' is present\n",
    "                \n",
    "\n",
    "                entry = pd.DataFrame([[jobID, data_path, filename]], columns = col) #create single job entry\n",
    "                output_path_df = output_path_df.append(entry, ignore_index = True)  #append job entry to job dataframe\n",
    "            \n",
    "            else: \n",
    "                data_path = False  #if no filepath is found just set it to False\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f354fb-9af7-4a1e-b715-c6be27aa3ae6",
   "metadata": {},
   "source": [
    "## Add path to JobID and drop any empty paths and problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0766abb-3ae4-4368-a31a-464363fea917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: Problem, dtype: object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_df = output_path_df.set_index('JobID').combine_first(jobs_df.drop_duplicates().set_index('JobID')).reset_index() #fill in n0_global values according to kymin values\n",
    "\n",
    "jobs_df = jobs_df.dropna(subset=['JobName'])        #if the job has no JobName (it did not execute) delete that row\n",
    "\n",
    "jobs_df[\"Path\"].fillna(False, inplace = True)     #Replace blank paths with False\n",
    "jobs_df[\"Problem\"].fillna(False, inplace = True)  #Replace blank problem name with False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2859f2a8-e503-4db1-b0f1-c47998e78cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bbdab9-968e-4e73-8e55-81a1d77b9a2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afdb0ecb-c57d-4254-9dec-59f173c7f916",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/global/homes/j/joeschm/Notebooks/JobID_Generator')\n",
    "jobs_df.to_csv('test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1c37cf-c729-4f59-a146-e15ace666337",
   "metadata": {},
   "source": [
    "## Read Parameter Files and Get Important Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1719c06d-9c88-416f-be17-f9364e767fd6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_pars(filename):\n",
    "    #This function gets the reference values from the parameters file and outputs the reference omega value, istep_field, and n0_global\n",
    "    \n",
    "    suffix = filename[-4:]     #get 00xx suffix for omega file\n",
    "    par = Parameters()\n",
    "    par.Read_Pars('parameters_'+suffix)  #read parameter file\n",
    "\n",
    "    pars = par.pardict                   #create a dictionary of values\n",
    "       \n",
    "    return pars, suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25cfed40-bf9d-4536-b4c4-72eff2b441eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/global/homes/j/joeschm/IFS_scripts')\n",
    "from genetools import Parameters\n",
    "\n",
    "col = ['nz0', 'kymin', 'n0_global', 'istep_field', 'timelim'] #parameters to look for and append\n",
    "\n",
    "for path in jobs_df[\"Path\"]:\n",
    "    print(path)\n",
    "    \n",
    "    if path == False: #if no filepath exists\n",
    "        print('No filepath found')\n",
    "        \n",
    "    elif os.path.exists(path): #if path exists then cd into it\n",
    "        os.chdir(path)\n",
    "\n",
    "        for filename in os.listdir(os.getcwd()):\n",
    "            if filename.startswith(\"parameters_\"):\n",
    "                param_list = []     #reset list\n",
    "                pars, suffix = get_pars(filename)\n",
    "                \n",
    "                for key in col:       #cycle through keys in col list that are of interest\n",
    "                    if key in pars:   #if the key exists then append it to the list\n",
    "                        param_list.append(pars[key])\n",
    "                    else:\n",
    "                        param_list.append(False)\n",
    "\n",
    "                print(param_list)\n",
    "        \n",
    "    else: #if filepath exists but there are no contents inside\n",
    "        print('Filepath is empty!')\n",
    "\n",
    "        \n",
    "#https://stackoverflow.com/questions/68231398/create-and-fill-duplicate-dataframe-values-with-lists/68238253#68238253"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4ce34a-8c34-4dca-a604-b017f9272ad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37b6724-ddc5-4931-a1b1-45da5261bcc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c631c43-a7f8-49d8-b382-1b2e3b8168d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f804c78a-4d6c-4330-a625-f09f46d047ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87fd3b4-a74f-441e-8c0a-7e6ee40982c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
